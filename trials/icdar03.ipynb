{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import sys\n",
    "import pylab\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cPickle as pkl\n",
    "from lasagne import layers\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from lasagne import updates\n",
    "from theano.tensor.nnet import softmax\n",
    "from scipy.misc import imread, imresize\n",
    "from nolearn.lasagne import NeuralNet, BatchIterator\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "repo_location = '/workspace/project/project/'\n",
    "data_root = os.path.join(os.path.expanduser('~') + repo_location + 'datasets/')\n",
    "script_root = os.path.join(os.path.expanduser('~') + repo_location + 'scripts/')\n",
    "model_root = os.path.join(os.path.expanduser('~') + repo_location + 'models/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded icdar03\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "train_soup = bs(open(data_root + 'icdar03/train/char/char.xml').read(), 'lxml-xml')\n",
    "test_soup = bs(open(data_root + 'icdar03/test/char/char.xml').read(), 'lxml-xml')\n",
    "\n",
    "X_train = []\n",
    "y_train = []\n",
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "for image in train_soup('image'):\n",
    "    try:\n",
    "        img = imread(data_root + 'icdar03/train/char/' + image['file'])\n",
    "        X_train.append(img)\n",
    "        y_train.append(image['tag'])\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "for image in test_soup('image'):\n",
    "    try:\n",
    "        img = imread(data_root + 'icdar03/test/char/' + image['file'])\n",
    "        X_test.append(img)\n",
    "        y_test.append(image['tag'])\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    \n",
    "data_train = pd.DataFrame({'image' : X_train, 'label' : y_train})\n",
    "data_test = pd.DataFrame({'image' : X_test, 'label' : y_test})\n",
    "\n",
    "print 'Loaded icdar03'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "icdar03 reshaped and grayscaled\n"
     ]
    }
   ],
   "source": [
    "# Reshape images to 32x32 and convert to grayscale\n",
    "data_train_x = np.zeros((data_train['image'].count(), 1, 32, 32))\n",
    "data_train_y = data_train['label'].values\n",
    "data_test_x = np.zeros((data_test['image'].count(), 1, 32, 32))\n",
    "data_test_y = data_test['label'].values\n",
    "\n",
    "for idx, img in enumerate(data_train['image']):\n",
    "    img = imresize(img, (32, 32))\n",
    "    if len(img.shape) == 3:\n",
    "        data_train_x[idx, ...] = img.dot([0.299, 0.587, 0.144])\n",
    "    else:\n",
    "        data_train_x[idx, ...] = img\n",
    "        \n",
    "for idx, img in enumerate(data_test['image']):\n",
    "    img = imresize(img, (32, 32))\n",
    "    if len(img.shape) == 3:\n",
    "        data_test_x[idx, ...] = img.dot([0.299, 0.587, 0.144])\n",
    "    else:\n",
    "        data_test_x[idx, ...] = img\n",
    "        \n",
    "data_train_x = data_train_x.astype('float32')\n",
    "data_test_x = data_test_x.astype('float32')\n",
    "print 'icdar03 reshaped and grayscaled'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normalize by MuSigma\n",
    "data_train_x /= data_train_x.std(axis = None)\n",
    "data_train_x -= data_train_x.mean()\n",
    "\n",
    "data_test_x /= data_test_x.std(axis = None)\n",
    "data_test_x -= data_test_x.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6185, 1, 32, 32) (6185,) (5430, 1, 32, 32) (5430,)\n"
     ]
    }
   ],
   "source": [
    "print data_train_x.shape, data_train_y.shape, data_test_x.shape, data_test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# setting nn \n",
    "net = NeuralNet(\n",
    "    layers = [\n",
    "        ('input', layers.InputLayer),\n",
    "        ('conv1', layers.Conv2DLayer),\n",
    "        ('pool1', layers.MaxPool2DLayer),\n",
    "        ('dropout1', layers.DropoutLayer),\n",
    "        ('conv2', layers.Conv2DLayer),\n",
    "        ('pool2', layers.MaxPool2DLayer),\n",
    "        ('dropout2', layers.DropoutLayer),\n",
    "        ('conv3', layers.Conv2DLayer),\n",
    "        ('dropout3', layers.DropoutLayer),\n",
    "        ('hidden4', layers.DenseLayer),\n",
    "        ('output', layers.DenseLayer),\n",
    "    ],\n",
    "\n",
    "    input_shape = (None, 1, 32, 32),\n",
    "    conv1_num_filters = 32, conv1_filter_size = (5, 5),\n",
    "    pool1_pool_size = (2, 2),\n",
    "    dropout1_p = 0.2,\n",
    "    conv2_num_filters = 64, conv2_filter_size = (5, 5),\n",
    "    pool2_pool_size = (2, 2),\n",
    "    dropout2_p = 0.3,\n",
    "    conv3_num_filters = 128, conv3_filter_size = (5, 5),\n",
    "    dropout3_p = 0.5,\n",
    "    hidden4_num_units = 128,\n",
    "    output_num_units = 75, output_nonlinearity = softmax,\n",
    "\n",
    "    batch_iterator_train = BatchIterator(batch_size = 2500),\n",
    "    batch_iterator_test = BatchIterator(batch_size = 2500),\n",
    "\n",
    "    update = updates.adam,\n",
    "\n",
    "    use_label_encoder = True,\n",
    "    regression = False,\n",
    "    max_epochs = 250,\n",
    "    verbose = 1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Neural Network with 283211 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name      size\n",
      "---  --------  --------\n",
      "  0  input     1x32x32\n",
      "  1  conv1     32x28x28\n",
      "  2  pool1     32x14x14\n",
      "  3  dropout1  32x14x14\n",
      "  4  conv2     64x10x10\n",
      "  5  pool2     64x5x5\n",
      "  6  dropout2  64x5x5\n",
      "  7  conv3     128x1x1\n",
      "  8  dropout3  128x1x1\n",
      "  9  hidden4   128\n",
      " 10  output    75\n",
      "\n",
      "  epoch    train loss    valid loss    train/val    valid acc  dur\n",
      "-------  ------------  ------------  -----------  -----------  -----\n",
      "      1       \u001b[36m4.32183\u001b[0m       \u001b[32m4.27056\u001b[0m      1.01200      0.04413  4.75s\n",
      "      2       \u001b[36m4.22851\u001b[0m       \u001b[32m4.16485\u001b[0m      1.01528      0.04413  4.75s\n",
      "      3       \u001b[36m4.15465\u001b[0m       \u001b[32m4.09075\u001b[0m      1.01562      0.04413  4.75s\n",
      "      4       \u001b[36m4.06992\u001b[0m       \u001b[32m4.03824\u001b[0m      1.00784      0.05280  4.75s\n",
      "      5       \u001b[36m3.99841\u001b[0m       \u001b[32m3.96425\u001b[0m      1.00862      0.05122  4.89s\n",
      "      6       \u001b[36m3.93319\u001b[0m       \u001b[32m3.92009\u001b[0m      1.00334      0.07565  4.75s\n",
      "      7       \u001b[36m3.87958\u001b[0m       \u001b[32m3.90817\u001b[0m      0.99268      0.09062  4.75s\n",
      "      8       \u001b[36m3.83237\u001b[0m       \u001b[32m3.88200\u001b[0m      0.98722      0.09850  4.75s\n",
      "      9       \u001b[36m3.77797\u001b[0m       \u001b[32m3.83203\u001b[0m      0.98589      0.10717  4.75s\n",
      "     10       \u001b[36m3.73284\u001b[0m       \u001b[32m3.79821\u001b[0m      0.98279      0.10796  4.88s\n",
      "     11       \u001b[36m3.67687\u001b[0m       \u001b[32m3.77306\u001b[0m      0.97451      0.12687  6.26s\n",
      "     12       \u001b[36m3.61833\u001b[0m       \u001b[32m3.72631\u001b[0m      0.97102      0.13633  5.35s\n",
      "     13       \u001b[36m3.54977\u001b[0m       \u001b[32m3.66712\u001b[0m      0.96800      0.14500  5.20s\n",
      "     14       \u001b[36m3.46664\u001b[0m       \u001b[32m3.61100\u001b[0m      0.96002      0.16785  5.55s\n",
      "     15       \u001b[36m3.40358\u001b[0m       \u001b[32m3.56057\u001b[0m      0.95591      0.18597  5.18s\n",
      "     16       \u001b[36m3.31904\u001b[0m       \u001b[32m3.49582\u001b[0m      0.94943      0.21592  5.46s\n",
      "     17       \u001b[36m3.25480\u001b[0m       \u001b[32m3.41791\u001b[0m      0.95228      0.24113  5.38s\n",
      "     18       \u001b[36m3.19128\u001b[0m       \u001b[32m3.36571\u001b[0m      0.94817      0.27029  5.53s\n",
      "     19       \u001b[36m3.08809\u001b[0m       \u001b[32m3.28081\u001b[0m      0.94126      0.28842  5.32s\n",
      "     20       \u001b[36m3.02127\u001b[0m       \u001b[32m3.18730\u001b[0m      0.94791      0.31836  5.25s\n",
      "     21       \u001b[36m2.95705\u001b[0m       \u001b[32m3.12460\u001b[0m      0.94638      0.34358  4.98s\n",
      "     22       \u001b[36m2.86463\u001b[0m       \u001b[32m3.05002\u001b[0m      0.93922      0.37431  4.75s\n",
      "     23       \u001b[36m2.77721\u001b[0m       \u001b[32m2.94888\u001b[0m      0.94178      0.39480  4.75s\n",
      "     24       \u001b[36m2.69456\u001b[0m       \u001b[32m2.84834\u001b[0m      0.94601      0.40504  4.75s\n",
      "     25       \u001b[36m2.60401\u001b[0m       \u001b[32m2.76438\u001b[0m      0.94199      0.42553  4.75s\n",
      "     26       \u001b[36m2.54131\u001b[0m       \u001b[32m2.69359\u001b[0m      0.94347      0.43814  4.78s\n",
      "     27       \u001b[36m2.47610\u001b[0m       \u001b[32m2.64042\u001b[0m      0.93777      0.46020  4.75s\n",
      "     28       \u001b[36m2.40560\u001b[0m       \u001b[32m2.54217\u001b[0m      0.94628      0.47675  4.76s\n",
      "     29       \u001b[36m2.33655\u001b[0m       \u001b[32m2.46119\u001b[0m      0.94936      0.49015  5.62s\n",
      "     30       \u001b[36m2.27541\u001b[0m       \u001b[32m2.39364\u001b[0m      0.95061      0.49567  5.39s\n",
      "     31       \u001b[36m2.21624\u001b[0m       \u001b[32m2.34397\u001b[0m      0.94551      0.50433  4.75s\n",
      "     32       \u001b[36m2.14427\u001b[0m       \u001b[32m2.29574\u001b[0m      0.93402      0.51615  4.86s\n",
      "     33       \u001b[36m2.10498\u001b[0m       \u001b[32m2.23429\u001b[0m      0.94212      0.53191  5.01s\n",
      "     34       \u001b[36m2.03690\u001b[0m       \u001b[32m2.16045\u001b[0m      0.94281      0.54137  5.16s\n",
      "     35       \u001b[36m1.99005\u001b[0m       \u001b[32m2.10491\u001b[0m      0.94543      0.55004  4.81s\n",
      "     36       \u001b[36m1.92424\u001b[0m       \u001b[32m2.06580\u001b[0m      0.93147      0.55792  5.60s\n",
      "     37       \u001b[36m1.91736\u001b[0m       \u001b[32m2.02185\u001b[0m      0.94832      0.56738  5.03s\n",
      "     38       \u001b[36m1.85602\u001b[0m       \u001b[32m1.97047\u001b[0m      0.94192      0.57762  4.82s\n",
      "     39       \u001b[36m1.80337\u001b[0m       \u001b[32m1.91850\u001b[0m      0.93999      0.59102  5.22s\n",
      "     40       \u001b[36m1.77792\u001b[0m       \u001b[32m1.88014\u001b[0m      0.94563      0.59653  4.92s\n",
      "     41       \u001b[36m1.72681\u001b[0m       \u001b[32m1.83440\u001b[0m      0.94135      0.60441  5.19s\n",
      "     42       \u001b[36m1.68348\u001b[0m       \u001b[32m1.80804\u001b[0m      0.93111      0.60599  5.02s\n",
      "     43       1.68449       \u001b[32m1.77872\u001b[0m      0.94703      0.61072  5.60s\n",
      "     44       \u001b[36m1.63867\u001b[0m       \u001b[32m1.75196\u001b[0m      0.93533      0.62096  5.66s\n",
      "     45       \u001b[36m1.60932\u001b[0m       \u001b[32m1.71983\u001b[0m      0.93575      0.62096  5.17s\n",
      "     46       \u001b[36m1.57617\u001b[0m       \u001b[32m1.67809\u001b[0m      0.93926      0.62884  5.37s\n",
      "     47       \u001b[36m1.52574\u001b[0m       \u001b[32m1.65103\u001b[0m      0.92412      0.63830  4.76s\n",
      "     48       \u001b[36m1.48605\u001b[0m       \u001b[32m1.62827\u001b[0m      0.91266      0.64224  4.93s\n",
      "     49       1.49585       \u001b[32m1.60769\u001b[0m      0.93043      0.64697  5.37s\n",
      "     50       \u001b[36m1.46544\u001b[0m       \u001b[32m1.59197\u001b[0m      0.92052      0.65091  5.03s\n",
      "     51       \u001b[36m1.44619\u001b[0m       \u001b[32m1.57813\u001b[0m      0.91639      0.65327  5.46s\n",
      "     52       \u001b[36m1.42926\u001b[0m       \u001b[32m1.54988\u001b[0m      0.92218      0.66036  5.19s\n",
      "     53       \u001b[36m1.41884\u001b[0m       \u001b[32m1.53514\u001b[0m      0.92424      0.66036  5.42s\n",
      "     54       \u001b[36m1.36363\u001b[0m       \u001b[32m1.51654\u001b[0m      0.89917      0.66667  5.58s\n",
      "     55       \u001b[36m1.35618\u001b[0m       \u001b[32m1.49501\u001b[0m      0.90714      0.66745  4.76s\n",
      "     56       \u001b[36m1.34624\u001b[0m       \u001b[32m1.48961\u001b[0m      0.90376      0.66745  4.78s\n",
      "     57       \u001b[36m1.33774\u001b[0m       \u001b[32m1.46219\u001b[0m      0.91489      0.67770  4.93s\n",
      "     58       \u001b[36m1.29660\u001b[0m       \u001b[32m1.43656\u001b[0m      0.90257      0.68006  5.11s\n",
      "     59       \u001b[36m1.29260\u001b[0m       1.45156      0.89049      0.67928  4.86s\n",
      "     60       \u001b[36m1.26615\u001b[0m       \u001b[32m1.43257\u001b[0m      0.88383      0.68637  5.27s\n",
      "     61       \u001b[36m1.23543\u001b[0m       \u001b[32m1.40636\u001b[0m      0.87846      0.68952  4.75s\n",
      "     62       1.23904       1.40662      0.88086      0.68637  4.75s\n",
      "     63       \u001b[36m1.22266\u001b[0m       \u001b[32m1.38811\u001b[0m      0.88081      0.68873  4.75s\n",
      "     64       \u001b[36m1.19509\u001b[0m       \u001b[32m1.38080\u001b[0m      0.86550      0.68558  4.75s\n",
      "     65       \u001b[36m1.18059\u001b[0m       1.38559      0.85205      0.68952  4.75s\n",
      "     66       1.19025       \u001b[32m1.37744\u001b[0m      0.86411      0.69504  4.75s\n",
      "     67       \u001b[36m1.17691\u001b[0m       \u001b[32m1.34925\u001b[0m      0.87227      0.69425  4.75s\n",
      "     68       \u001b[36m1.16066\u001b[0m       \u001b[32m1.34783\u001b[0m      0.86114      0.69504  4.75s\n",
      "     69       \u001b[36m1.13461\u001b[0m       \u001b[32m1.33993\u001b[0m      0.84677      0.69898  4.75s\n",
      "     70       1.13961       1.34009      0.85039      0.70055  4.75s\n",
      "     71       \u001b[36m1.12102\u001b[0m       \u001b[32m1.33116\u001b[0m      0.84214      0.70292  5.37s\n",
      "     72       \u001b[36m1.11487\u001b[0m       \u001b[32m1.31818\u001b[0m      0.84576      0.70213  4.75s\n",
      "     73       \u001b[36m1.09976\u001b[0m       \u001b[32m1.31812\u001b[0m      0.83434      0.70370  4.75s\n",
      "     74       \u001b[36m1.08660\u001b[0m       \u001b[32m1.30241\u001b[0m      0.83430      0.70686  4.87s\n",
      "     75       \u001b[36m1.05870\u001b[0m       \u001b[32m1.30096\u001b[0m      0.81378      0.71316  4.75s\n",
      "     76       \u001b[36m1.03977\u001b[0m       \u001b[32m1.29153\u001b[0m      0.80507      0.71080  4.94s\n",
      "     77       1.05270       \u001b[32m1.28091\u001b[0m      0.82184      0.71080  5.88s\n",
      "     78       1.04080       1.28608      0.80928      0.70134  4.99s\n",
      "     79       \u001b[36m1.03346\u001b[0m       1.28268      0.80570      0.70528  4.80s\n",
      "     80       \u001b[36m1.01650\u001b[0m       \u001b[32m1.27659\u001b[0m      0.79626      0.70843  4.89s\n",
      "     81       1.02025       \u001b[32m1.27423\u001b[0m      0.80067      0.71080  5.19s\n",
      "     82       \u001b[36m0.99115\u001b[0m       \u001b[32m1.26996\u001b[0m      0.78046      0.70922  4.80s\n",
      "     83       1.00762       \u001b[32m1.26754\u001b[0m      0.79494      0.71474  4.89s\n",
      "     84       \u001b[36m0.98621\u001b[0m       \u001b[32m1.25564\u001b[0m      0.78542      0.71158  5.10s\n",
      "     85       0.99656       \u001b[32m1.25221\u001b[0m      0.79584      0.71474  5.42s\n",
      "     86       \u001b[36m0.97485\u001b[0m       1.25782      0.77503      0.71946  5.12s\n",
      "     87       \u001b[36m0.94221\u001b[0m       \u001b[32m1.24595\u001b[0m      0.75622      0.71395  5.15s\n",
      "     88       0.96210       1.24620      0.77203      0.71946  4.84s\n",
      "     89       \u001b[36m0.93766\u001b[0m       \u001b[32m1.24066\u001b[0m      0.75578      0.71631  4.75s\n",
      "     90       0.94524       \u001b[32m1.23259\u001b[0m      0.76688      0.71631  4.75s\n",
      "     91       \u001b[36m0.91670\u001b[0m       \u001b[32m1.23128\u001b[0m      0.74451      0.71631  4.75s\n",
      "     92       0.92216       1.24438      0.74106      0.71552  4.75s\n",
      "     93       0.92560       \u001b[32m1.23038\u001b[0m      0.75229      0.71631  4.75s\n",
      "     94       \u001b[36m0.91083\u001b[0m       \u001b[32m1.22005\u001b[0m      0.74655      0.72104  4.75s\n",
      "     95       \u001b[36m0.90028\u001b[0m       1.22165      0.73694      0.71946  4.75s\n",
      "     96       0.90212       \u001b[32m1.21661\u001b[0m      0.74150      0.71789  5.70s\n",
      "     97       \u001b[36m0.89726\u001b[0m       1.21675      0.73742      0.72025  5.69s\n",
      "     98       \u001b[36m0.89028\u001b[0m       1.22316      0.72786      0.72892  5.82s\n",
      "     99       \u001b[36m0.87131\u001b[0m       \u001b[32m1.21219\u001b[0m      0.71879      0.72183  5.37s\n",
      "    100       0.87289       \u001b[32m1.21157\u001b[0m      0.72046      0.72104  5.01s\n",
      "    101       \u001b[36m0.85966\u001b[0m       \u001b[32m1.19949\u001b[0m      0.71669      0.72971  4.98s\n",
      "    102       \u001b[36m0.85919\u001b[0m       1.20782      0.71135      0.72577  4.88s\n",
      "    103       \u001b[36m0.84332\u001b[0m       \u001b[32m1.19313\u001b[0m      0.70681      0.72104  4.74s\n",
      "    104       0.85112       \u001b[32m1.19079\u001b[0m      0.71475      0.73050  4.74s\n",
      "    105       \u001b[36m0.84150\u001b[0m       1.19678      0.70314      0.72813  4.74s\n",
      "    106       0.85303       1.20141      0.71002      0.72971  4.76s\n",
      "    107       \u001b[36m0.83738\u001b[0m       1.20050      0.69753      0.72498  4.75s\n",
      "    108       \u001b[36m0.81901\u001b[0m       1.20622      0.67899      0.72577  4.75s\n",
      "    109       \u001b[36m0.81035\u001b[0m       1.21089      0.66922      0.72419  4.89s\n",
      "    110       0.82808       1.20796      0.68552      0.72892  5.64s\n",
      "    111       \u001b[36m0.80638\u001b[0m       1.19674      0.67382      0.73601  5.27s\n",
      "    112       0.81754       1.19361      0.68493      0.72971  4.84s\n",
      "    113       0.80771       1.19149      0.67790      0.72971  4.92s\n",
      "    114       \u001b[36m0.80420\u001b[0m       1.20529      0.66723      0.73444  5.66s\n",
      "    115       \u001b[36m0.79786\u001b[0m       \u001b[32m1.18596\u001b[0m      0.67276      0.73916  4.77s\n",
      "    116       \u001b[36m0.79187\u001b[0m       \u001b[32m1.17805\u001b[0m      0.67218      0.73759  4.83s\n",
      "    117       \u001b[36m0.78863\u001b[0m       1.17892      0.66894      0.73759  5.13s\n",
      "    118       \u001b[36m0.78003\u001b[0m       \u001b[32m1.17513\u001b[0m      0.66378      0.73444  6.13s\n",
      "    119       0.78411       \u001b[32m1.17300\u001b[0m      0.66846      0.73680  5.56s\n",
      "    120       \u001b[36m0.76166\u001b[0m       1.17907      0.64598      0.74153  5.12s\n",
      "    121       0.78251       1.18149      0.66231      0.73916  5.44s\n",
      "    122       \u001b[36m0.75284\u001b[0m       1.18368      0.63601      0.73680  5.04s\n",
      "    123       \u001b[36m0.74560\u001b[0m       1.17705      0.63345      0.73680  4.75s\n",
      "    124       0.74888       1.17919      0.63508      0.73680  4.90s\n",
      "    125       \u001b[36m0.74301\u001b[0m       1.17740      0.63106      0.74547  4.93s\n",
      "    126       \u001b[36m0.73076\u001b[0m       \u001b[32m1.16048\u001b[0m      0.62970      0.74626  5.08s\n",
      "    127       \u001b[36m0.73029\u001b[0m       1.16080      0.62912      0.74941  4.74s\n",
      "    128       \u001b[36m0.71668\u001b[0m       1.17198      0.61151      0.75099  4.74s\n",
      "    129       0.72709       1.16191      0.62577      0.74704  5.09s\n",
      "    130       0.73592       1.18043      0.62343      0.74626  4.76s\n",
      "    131       0.72373       1.16973      0.61871      0.74704  4.75s\n",
      "    132       \u001b[36m0.71660\u001b[0m       1.18694      0.60373      0.73207  4.75s\n",
      "    133       \u001b[36m0.71044\u001b[0m       1.18646      0.59879      0.73207  4.75s\n",
      "    134       \u001b[36m0.68145\u001b[0m       1.18417      0.57547      0.73286  4.75s\n",
      "    135       0.70285       1.18136      0.59495      0.73838  4.75s\n",
      "    136       0.69301       1.18509      0.58478      0.74389  4.75s\n",
      "    137       0.68734       1.18799      0.57857      0.73995  4.75s\n",
      "    138       0.70566       1.18123      0.59739      0.74074  4.75s\n",
      "    139       0.69370       1.17603      0.58986      0.74547  4.75s\n",
      "    140       0.69438       1.17557      0.59067      0.74468  4.75s\n",
      "    141       0.69000       1.17035      0.58956      0.74389  4.75s\n",
      "    142       \u001b[36m0.67580\u001b[0m       1.17248      0.57638      0.74468  4.75s\n",
      "    143       0.69747       1.18527      0.58845      0.74310  4.76s\n",
      "    144       \u001b[36m0.66864\u001b[0m       1.18222      0.56558      0.74626  4.82s\n",
      "    145       0.68017       1.17029      0.58120      0.74468  4.76s\n"
     ]
    }
   ],
   "source": [
    "# train nn\n",
    "net.fit(data_train_x, data_train_y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.734069981584\n"
     ]
    }
   ],
   "source": [
    "pred = net.predict(data_test_x)\n",
    "print accuracy_score(data_test_y, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          !       0.40      0.25      0.31         8\n",
      "          \"       0.00      0.00      0.00         1\n",
      "          &       1.00      0.14      0.25         7\n",
      "          '       0.00      0.00      0.00         8\n",
      "          (       0.00      0.00      0.00         1\n",
      "          )       0.00      0.00      0.00         1\n",
      "          ,       0.00      0.00      0.00         6\n",
      "          -       1.00      0.25      0.40         4\n",
      "          .       0.14      0.09      0.11        11\n",
      "          0       0.00      0.00      0.00        46\n",
      "          1       0.91      0.43      0.59        46\n",
      "          2       0.72      0.78      0.75        49\n",
      "          3       1.00      0.41      0.58        17\n",
      "          4       0.62      0.33      0.43        24\n",
      "          5       0.44      0.28      0.34        29\n",
      "          6       0.89      0.53      0.67        15\n",
      "          7       0.00      0.00      0.00        10\n",
      "          8       0.50      0.17      0.25         6\n",
      "          9       1.00      0.07      0.12        15\n",
      "          ?       0.00      0.00      0.00         1\n",
      "          A       0.90      0.89      0.89       223\n",
      "          B       0.72      0.66      0.69        47\n",
      "          C       0.79      0.76      0.77       153\n",
      "          D       0.75      0.72      0.73        74\n",
      "          E       0.77      0.86      0.82       322\n",
      "          F       0.77      0.79      0.78        76\n",
      "          G       0.73      0.70      0.72        63\n",
      "          H       0.93      0.88      0.90        97\n",
      "          I       0.52      0.56      0.54       163\n",
      "          J       0.50      0.31      0.38        13\n",
      "          K       0.96      0.52      0.68        46\n",
      "          L       0.73      0.82      0.77       131\n",
      "          M       0.77      0.81      0.79        89\n",
      "          N       0.93      0.82      0.87       153\n",
      "          O       0.63      0.73      0.68       187\n",
      "          P       0.86      0.66      0.75        91\n",
      "          Q       0.00      0.00      0.00         4\n",
      "          R       0.81      0.79      0.80       205\n",
      "          S       0.79      0.80      0.79       229\n",
      "          T       0.86      0.78      0.82       205\n",
      "          U       0.75      0.74      0.74        92\n",
      "          V       0.64      0.62      0.63        26\n",
      "          W       0.74      0.82      0.78        39\n",
      "          X       0.94      0.84      0.89        19\n",
      "          Y       0.90      0.83      0.86        42\n",
      "          Z       0.00      0.00      0.00         7\n",
      "          a       0.72      0.79      0.75       171\n",
      "          b       0.64      0.58      0.61        24\n",
      "          c       0.70      0.56      0.62       100\n",
      "          d       0.88      0.70      0.78        54\n",
      "          e       0.73      0.82      0.77       331\n",
      "          f       0.79      0.64      0.71        47\n",
      "          g       0.63      0.63      0.63        38\n",
      "          h       0.91      0.69      0.78        86\n",
      "          i       0.65      0.81      0.72       182\n",
      "          j       0.00      0.00      0.00         4\n",
      "          k       0.71      0.67      0.69        33\n",
      "          l       0.29      0.40      0.34       105\n",
      "          m       0.72      0.84      0.77        51\n",
      "          n       0.74      0.93      0.83       162\n",
      "          o       0.70      0.61      0.65       194\n",
      "          p       0.71      0.62      0.67        56\n",
      "          q       0.00      0.00      0.00         3\n",
      "          r       0.67      0.90      0.76       177\n",
      "          s       0.69      0.84      0.76       154\n",
      "          t       0.77      0.83      0.80       173\n",
      "          u       0.71      0.70      0.71        67\n",
      "          v       0.57      0.54      0.55        24\n",
      "          w       0.73      0.58      0.65        19\n",
      "          x       0.58      0.58      0.58        12\n",
      "          y       0.71      0.65      0.68        57\n",
      "          z       0.00      0.00      0.00         2\n",
      "          £       0.00      0.00      0.00         3\n",
      "\n",
      "avg / total       0.73      0.73      0.73      5430\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print classification_report(data_test_y, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
